{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "ULkrDzxGq9VQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-kAYN0vq3Bo"
      },
      "outputs": [],
      "source": [
        "# utils\n",
        "from torchvision import datasets\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from datetime import datetime\n",
        "import wandb\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from torchvision import models\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "from dataclasses import dataclass\n",
        "from torch.optim.lr_scheduler import StepLR, MultiStepLR, CosineAnnealingLR\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def set_random_seed(seed):\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "\n",
        "class WanDBWriter:\n",
        "    def __init__(self, config):\n",
        "        self.writer = None\n",
        "        self.selected_module = \"\"\n",
        "\n",
        "        wandb.login()\n",
        "\n",
        "        if not hasattr(config, 'wandb_project'):\n",
        "            raise ValueError(\"please specify project name for wandb\")\n",
        "\n",
        "        wandb.init(\n",
        "            project=getattr(config, 'wandb_project'),\n",
        "            config=config\n",
        "        )\n",
        "        self.wandb = wandb\n",
        "\n",
        "        self.step = 0\n",
        "        self.mode = \"\"\n",
        "        self.timer = datetime.now()\n",
        "\n",
        "    def set_step(self, step, mode=\"train\"):\n",
        "        self.mode = mode\n",
        "        self.step = step\n",
        "        if step == 0:\n",
        "            self.timer = datetime.now()\n",
        "        else:\n",
        "            duration = datetime.now() - self.timer\n",
        "            self.add_scalar(\"steps_per_sec\", 1 / duration.total_seconds())\n",
        "            self.timer = datetime.now()\n",
        "\n",
        "    def finish(self):\n",
        "        wandb.finish()\n",
        "\n",
        "    def scalar_name(self, scalar_name):\n",
        "        return f\"{self.mode}/{scalar_name}\"\n",
        "\n",
        "    def watch_model(self, model, criterion=None):\n",
        "        self.wandb.watch(model)\n",
        "\n",
        "    def add_scalar(self, scalar_name, scalar):\n",
        "        self.wandb.log({\n",
        "            self.scalar_name(scalar_name): scalar,\n",
        "        }, step=self.step)\n",
        "\n",
        "    def add_scalars(self, tag, scalars):\n",
        "        self.wandb.log({\n",
        "            **{f\"{scalar_name}_{tag}_{self.mode}\": scalar for scalar_name, scalar in scalars.items()}\n",
        "        }, step=self.step)\n",
        "\n",
        "    def add_image(self, scalar_name, image):\n",
        "        self.wandb.log({\n",
        "            self.scalar_name(scalar_name): self.wandb.Image(image)\n",
        "        }, step=self.step)\n",
        "\n",
        "    def add_audio(self, scalar_name, audio, sample_rate=None):\n",
        "        # audio = audio.detach().cpu().numpy().T\n",
        "        audio = audio.T\n",
        "        self.wandb.log({\n",
        "            self.scalar_name(scalar_name): self.wandb.Audio(audio, sample_rate=sample_rate)\n",
        "        }, step=self.step)\n",
        "\n",
        "    def add_text(self, scalar_name, text):\n",
        "        self.wandb.log({\n",
        "            self.scalar_name(scalar_name): self.wandb.Html(text)\n",
        "        }, step=self.step)\n",
        "\n",
        "    def add_pr_curve(self, scalar_name, scalar):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def add_embedding(self, scalar_name, scalar):\n",
        "        raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Supervised Baseline"
      ],
      "metadata": {
        "id": "iVDH-wrQrCe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = T.Compose([\n",
        "    T.RandomResizedCrop(224),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    # T.Resize((h,w))\n",
        "])\n",
        "\n",
        "test_transforms = T.Compose([\n",
        "    T.Resize(256),\n",
        "    T.CenterCrop(224),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "68ePkP-TrBCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class SupervisedBaselineConfig:\n",
        "    wandb_project = 'SLL_HW2'\n",
        "    num_workers = 2\n",
        "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "    seed = 3407\n",
        "\n",
        "    num_epochs = 90\n",
        "    save_epochs = 10\n",
        "    batch_size = 256\n",
        "    optim = 'SGD'\n",
        "    lr = 0.1\n",
        "    momentum = 0.9\n",
        "    nesterov = False\n",
        "    weight_decay = 1e-4\n",
        "\n",
        "    scheduler = 'MultiStepLR'\n",
        "    milestones = [30, 50, 70, 80]\n",
        "    gamma = 0.1"
      ],
      "metadata": {
        "id": "d3CKzfQmrGhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = SupervisedBaselineConfig()\n",
        "set_random_seed(config.seed)\n",
        "train_dataset = datasets.STL10('data', 'train', download=True, transform=train_transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=True)\n",
        "test_dataset = datasets.STL10('data', 'test', download=True, transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True)\n",
        "\n",
        "model = models.resnet18(num_classes=10)\n",
        "model = model.to(config.device)\n",
        "\n",
        "# loss, optimizer and hyperparameters\n",
        "current_step = 0\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=config.momentum,\n",
        "#                       weight_decay=config.weight_decay, nesterov=True)\n",
        "optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=config.momentum,\n",
        "                      weight_decay=config.weight_decay, nesterov=config.nesterov)\n",
        "scheduler = MultiStepLR(optimizer, milestones=config.milestones, gamma=config.gamma)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "logger = WanDBWriter(config)\n",
        "# train\n",
        "tqdm_bar = tqdm(total=config.num_epochs * len(train_loader) - current_step)\n",
        "for epoch in range(config.num_epochs):\n",
        "    accuracy, loss = 0, 0\n",
        "    for i, (imgs, labels) in enumerate(train_loader):\n",
        "        current_step += 1\n",
        "        tqdm_bar.update(1)\n",
        "        logger.set_step(current_step)\n",
        "\n",
        "        imgs, labels = imgs.to(config.device), labels.to(config.device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "        # loss.backward()\n",
        "        # optimizer.step()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        accuracy += (predicted == labels).sum().item()\n",
        "        loss += loss.item()\n",
        "    \n",
        "    scheduler.step()\n",
        "    logger.add_scalar('train/loss', loss / len(train_loader))\n",
        "    logger.add_scalar('train/accuracy', accuracy / len(train_loader) / config.batch_size)\n",
        "    # logger.add_scalar('lr', scheduler.get_last_lr())\n",
        "    logger.add_image(f'train/img0', imgs[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "    logger.add_image(f'train/img1', imgs[1].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "    logger.add_image(f'train/img2', imgs[2].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "\n",
        "    # evaluate\n",
        "    model.eval()\n",
        "    accuracy, loss = 0, 0\n",
        "    for i, (imgs, labels) in enumerate(test_loader):\n",
        "        imgs, labels = imgs.to(config.device), labels.to(config.device)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            with torch.no_grad():\n",
        "                outputs = model(imgs)\n",
        "                loss = criterion(outputs, labels)\n",
        "        \n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        accuracy += (predicted == labels).sum().item()\n",
        "        loss += loss.item()\n",
        "    \n",
        "    logger.add_scalar('test/loss', loss / len(test_loader))\n",
        "    logger.add_scalar('test/accuracy', accuracy / len(test_loader) / config.batch_size)\n",
        "    logger.add_image(f'test/img0', imgs[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "    logger.add_image(f'test/img1', imgs[1].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "    logger.add_image(f'test/img2', imgs[2].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "    model.train()\n",
        "\n",
        "    if config.save_epochs != 0 and epoch % config.save_epochs == config.save_epochs - 1:\n",
        "        torch.save(model.state_dict(), f'model_{epoch}.pth')\n",
        "\n",
        "logger.finish()"
      ],
      "metadata": {
        "id": "nW8-VFLUrHmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SimCLR"
      ],
      "metadata": {
        "id": "BGvg5KZPrKHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = 1.0\n",
        "size = 96\n",
        "color_jitter = T.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
        "rnd_color_jitter = T.RandomApply([color_jitter], p=0.8)\n",
        "rnd_gray = T.RandomGrayscale(p=0.2)\n",
        "\n",
        "train_transforms = T.Compose([\n",
        "    T.RandomResizedCrop(size),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    rnd_color_jitter,\n",
        "    rnd_gray,\n",
        "    T.GaussianBlur(kernel_size=int(0.1 * 96)),\n",
        "    T.ToTensor(),\n",
        "])\n",
        "\n",
        "class ContrastiveImages():\n",
        "    def __init__(self, transform):\n",
        "        self.transform = transform\n",
        "        self.n_views = 2\n",
        "\n",
        "    def __call__(self, img):\n",
        "        return [self.transform(img) for i in range(self.n_views)]"
      ],
      "metadata": {
        "id": "oFJUKe0srIv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NCE_loss(nn.Module):\n",
        "    def __init__(self, config, temperature=0.1):\n",
        "        super(NCE_loss, self).__init__()\n",
        "        self.config = config\n",
        "        self.temperature = temperature\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.n_views = 2\n",
        "        self.shape = self.config.batch_size * self.n_views\n",
        "        self.diagonal = torch.eye(self.shape, dtype=torch.bool, device=self.config.device)\n",
        "        # print(self.diagonal.device, 'hey')\n",
        "    \n",
        "    def forward(self, outputs):\n",
        "        labels_matrix = [torch.arange(self.config.batch_size) for i in range(self.n_views)]\n",
        "        labels_matrix = torch.cat(labels_matrix, 0)\n",
        "        labels_matrix = (labels_matrix.unsqueeze(0) == labels_matrix.unsqueeze(1)).to(self.config.device)\n",
        "        # labels_matrix.to(self.config.device)\n",
        "        # print(self.config.device, labels_matrix.device, self.diagonal.device)\n",
        "        # print(labels_matrix.shape)\n",
        "        labels_matrix = labels_matrix[~self.diagonal].view(self.shape, -1)\n",
        "\n",
        "        outputs = F.normalize(outputs)\n",
        "\n",
        "        similarity = outputs @ outputs.T\n",
        "        # print(similarity.shape)\n",
        "        similarity = similarity[~self.diagonal].view(self.shape, -1)\n",
        "\n",
        "        negative = similarity[~labels_matrix.bool()].view(self.shape, -1) / self.temperature\n",
        "        positive = similarity[labels_matrix.bool()].view(self.shape, -1) / self.temperature\n",
        "\n",
        "        logits = torch.cat([positive, negative], dim=1)\n",
        "        labels = torch.zeros(self.shape, dtype=torch.long).to(self.config.device)\n",
        "        loss = self.criterion(logits, labels)\n",
        "        \n",
        "        return loss, logits, labels"
      ],
      "metadata": {
        "id": "OKPLZoO_rOjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class SimCLR_config:\n",
        "    wandb_project = 'SLL_HW2'\n",
        "    num_workers = 8\n",
        "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "    seed = 3407\n",
        "    \n",
        "    num_epochs = 200\n",
        "    save_epochs = 10\n",
        "    eval_epochs = 10\n",
        "    batch_size = 256\n",
        "    optim = 'Adam'\n",
        "    lr = 3e-4\n",
        "    weight_decay = 1e-4\n",
        "    \n",
        "    num_features = 512\n",
        "\n",
        "    scheduler = 'CosineAnnealingLR'"
      ],
      "metadata": {
        "id": "bnp1MvmOrPr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = SimCLR_config()\n",
        "set_random_seed(config.seed)\n",
        "\n",
        "train_dataset = datasets.STL10('data', 'unlabeled', download=True, transform=ContrastiveImages(train_transforms))\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=True)\n",
        "\n",
        "test_dataset = datasets.STL10('data', 'train', download=True, transform=ContrastiveImages(train_transforms))\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=True)\n",
        "\n",
        "model = models.resnet18(num_classes=config.num_features)\n",
        "in_features = model.fc.in_features\n",
        "projection_g = nn.Sequential(\n",
        "    nn.Linear(in_features, in_features),\n",
        "    nn.ReLU(),\n",
        "    model.fc\n",
        ")\n",
        "model.fc = projection_g\n",
        "model.to(config.device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=len(train_loader))\n",
        "\n",
        "# loss, optimizer and hyperparameters\n",
        "current_step = 0\n",
        "criterion = NCE_loss(config)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "logger = WanDBWriter(config)\n",
        "\n",
        "tqdm_bar = tqdm(total=config.num_epochs * len(train_loader) - current_step)\n",
        "for epoch in range(config.num_epochs):\n",
        "    for i, (imgs, _) in enumerate(train_loader):\n",
        "        current_step += 1\n",
        "        tqdm_bar.update(1)\n",
        "        logger.set_step(current_step)\n",
        "        imgs = torch.cat(imgs, dim=0).to(config.device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(imgs)\n",
        "            loss, logits, labels, = criterion(outputs)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        _, predicted = torch.max(logits.data, 1)\n",
        "        accuracy = (predicted == ).sum().item() / len(labels)\n",
        "\n",
        "        logger.add_scalar('accuracy', accuracy)\n",
        "        logger.add_scalar('loss', loss.item())\n",
        "    \n",
        "    if epoch >= 9:\n",
        "        scheduler.step()\n",
        "    \n",
        "    logger.add_scalar('lr', optimizer.param_groups[0][\"lr\"])\n",
        "    logger.add_image('img0', imgs[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "    logger.add_image('img1', imgs[1].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "    logger.add_image('img2', imgs[2].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "    \n",
        "    if config.eval_epochs != 0 and epoch % config.eval_epochs == config.eval_epochs - 1:\n",
        "        model.eval()\n",
        "        current_step_test = 0\n",
        "        for i, (imgs, labels) in enumerate(test_loader):\n",
        "            current_step_test += 1\n",
        "            logger.set_step(current_step, 'test')\n",
        "            imgs = torch.cat(imgs, dim=0).to(config.device)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(imgs)\n",
        "                    loss, logits, labels, = criterion(outputs)\n",
        "\n",
        "            _, predicted = torch.max(logits.data, 1)\n",
        "            accuracy = (predicted == labels).sum().item() / len(labels)\n",
        "\n",
        "            logger.add_scalar('loss', loss)\n",
        "            logger.add_scalar('accuracy', accuracy)\n",
        "\n",
        "        logger.add_image('img0', imgs[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        logger.add_image('img1', imgs[1].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        logger.add_image('img2', imgs[2].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        model.train()\n",
        "\n",
        "    if config.save_epochs != 0 and epoch % config.save_epochs == config.save_epochs - 1:\n",
        "        torch.save(model.state_dict(), f'model_SimCLR_2_{epoch}.pth')\n",
        "\n",
        "logger.finish()"
      ],
      "metadata": {
        "id": "zesvpfMyrauD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BYOL"
      ],
      "metadata": {
        "id": "SEFg5iXlrfau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = 1.0\n",
        "size = 96\n",
        "color_jitter = T.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
        "rnd_color_jitter = T.RandomApply([color_jitter], p=0.8)\n",
        "rnd_gray = T.RandomGrayscale(p=0.2)\n",
        "\n",
        "train_transforms = T.Compose([\n",
        "    T.RandomResizedCrop(size),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    rnd_color_jitter,\n",
        "    rnd_gray,\n",
        "    T.GaussianBlur(kernel_size=int(0.1 * 96)),\n",
        "    T.ToTensor(),\n",
        "])\n",
        "\n",
        "class ContrastiveImages():\n",
        "    def __init__(self, transform):\n",
        "        self.transform = transform\n",
        "        self.n_views = 2\n",
        "\n",
        "    def __call__(self, img):\n",
        "        return [self.transform(img) for i in range(self.n_views)]"
      ],
      "metadata": {
        "id": "0GXUfKZfrgFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class BYOL_config:\n",
        "    wandb_project = 'SLL_HW2'\n",
        "    num_workers = 16\n",
        "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "    seed = 3407\n",
        "\n",
        "    num_epochs = 1000\n",
        "    save_epochs = 20\n",
        "    eval_epochs = 20\n",
        "    batch_size = 512\n",
        "\n",
        "    optim = 'Adam'\n",
        "    lr = 3e-4\n",
        "    weight_decay = 1e-4\n",
        "\n",
        "    mlp_hidden_size = 4096\n",
        "    projection_size = 256\n",
        "    moving_average = 0.99\n",
        "\n",
        "    model_save_name = \"model_BYOL_oshibka\"\n",
        "    \n",
        "    scheduler = 'CosineAnnealingLR'"
      ],
      "metadata": {
        "id": "5swpRMiarhTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BYOL_loss(nn.Module):\n",
        "    def __init__(self, online_model, offline_model, projection):\n",
        "        super(BYOL_loss, self).__init__()\n",
        "        self.online_model = online_model\n",
        "        self.offline_model = offline_model\n",
        "        self.model_predict = model_predict\n",
        "\n",
        "    def regression_loss(self, x, y):\n",
        "        x = F.normalize(x, dim=1)\n",
        "        y = F.normalize(y, dim=1)\n",
        "        return 2 - 2 * (x * y).sum(dim=-1)\n",
        "\n",
        "    def forward(self, imgs_view1, imgs_view2):\n",
        "        # print(0)\n",
        "        online_network_out_1 = self.model_predict(self.online_model(imgs_view1))\n",
        "        # print(1)\n",
        "        z_std1 = self.online_model.z_std\n",
        "        online_network_out_2 = self.model_predict(self.online_model(imgs_view2))\n",
        "        z_std2 = self.online_model.z_std\n",
        "\n",
        "        with torch.no_grad():\n",
        "            offline_network_out_1 = self.offline_model(imgs_view1)\n",
        "            offline_network_out_2 = self.offline_model(imgs_view2)\n",
        "\n",
        "        loss1 = self.regression_loss(online_network_out_1, offline_network_out_2)\n",
        "        loss2 = self.regression_loss(online_network_out_2, offline_network_out_1)\n",
        "        # print(loss1.mean(), loss2.mean())\n",
        "\n",
        "        return (loss1 + loss2).mean(), z_std1, z_std2"
      ],
      "metadata": {
        "id": "1YUottrjricS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BYOL_network(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BYOL_network, self).__init__()\n",
        "        self.resnet = models.resnet18()\n",
        "        self.in_features = self.resnet.fc.in_features\n",
        "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(self.in_features, config.mlp_hidden_size),\n",
        "            nn.BatchNorm1d(config.mlp_hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(config.mlp_hidden_size, config.projection_size)\n",
        "        )\n",
        "        self.z_std = None\n",
        "    \n",
        "    def forward(self, img):\n",
        "        # print(img.shape)\n",
        "        z = self.resnet(img)\n",
        "        # print('z', z.shape)\n",
        "        z = z.view(z.shape[0], z.shape[1])\n",
        "        # print('z', z.shape)\n",
        "        self.z_std = z.std()\n",
        "        q_z = self.projection(z)\n",
        "        # print(q_z.shape)\n",
        "        return q_z"
      ],
      "metadata": {
        "id": "DVPm3FeYrjwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = BYOL_config()\n",
        "set_random_seed(config.seed)\n",
        "# loader\n",
        "train_dataset = datasets.STL10('data', 'unlabeled', download=True, transform=ContrastiveImages(train_transforms))\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=True)\n",
        "\n",
        "test_dataset = datasets.STL10('data', 'train', download=True, transform=ContrastiveImages(train_transforms))\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=True)\n",
        "# models\n",
        "model_online = BYOL_network(config)\n",
        "model_offline = BYOL_network(config)\n",
        "model_predict = nn.Sequential(\n",
        "    nn.Linear(config.projection_size, config.mlp_hidden_size),\n",
        "    nn.BatchNorm1d(config.mlp_hidden_size),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(config.mlp_hidden_size, config.projection_size)\n",
        ")\n",
        "model_online.to(config.device)\n",
        "model_offline.to(config.device)\n",
        "model_predict.to(config.device)\n",
        "\n",
        "for param_online, param_offline in zip(model_online.parameters(), model_offline.parameters()):\n",
        "    param_offline.data.copy_(param_online.data)\n",
        "    param_offline.requires_grad = False\n",
        "# loss, optimizer and hyperparameters\n",
        "optimizer = optim.Adam(list(model_online.parameters()) + list(model_predict.parameters()),\n",
        "                       lr=config.lr, weight_decay=config.weight_decay)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=len(train_loader))\n",
        "current_step = 0\n",
        "criterion = BYOL_loss(model_online, model_offline, model_predict)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "logger = WanDBWriter(config)\n",
        "# train\n",
        "tqdm_bar = tqdm(total=config.num_epochs * len(train_loader) - current_step)\n",
        "for epoch in range(config.num_epochs):\n",
        "    for i, ((imgs_view1, imgs_view2), label) in enumerate(train_loader):\n",
        "        current_step += 1\n",
        "        tqdm_bar.update(1)\n",
        "        logger.set_step(current_step)\n",
        "        imgs_view1, imgs_view2 = imgs_view1.to(config.device), imgs_view2.to(config.device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            loss, z_std1, z_std2 = criterion(imgs_view1, imgs_view2)\n",
        "            # print(loss)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        logger.add_scalar('loss', loss.item())\n",
        "        logger.add_scalar('std of z1', z_std1.item())\n",
        "        logger.add_scalar('std of z2', z_std2.item())\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for param_online, param_offline in zip(model_online.parameters(), model_offline.parameters()):\n",
        "                param_offline.data = (param_offline.data * config.moving_average\n",
        "                                      + param_online.data * (1.0 - config.moving_average))\n",
        "\n",
        "    if epoch >= 9:\n",
        "        scheduler.step()\n",
        "\n",
        "    logger.add_scalar('lr', optimizer.param_groups[0][\"lr\"])\n",
        "    logger.add_image('img0', imgs_view1[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "    logger.add_image('img1', imgs_view2[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "\n",
        "    # evaluate\n",
        "    if config.eval_epochs != 0 and epoch % config.eval_epochs == config.eval_epochs - 1:\n",
        "        model_online.eval()\n",
        "        model_predict.eval()\n",
        "        current_step_test = 0\n",
        "        for i, ((imgs_view1, imgs_view2), label) in enumerate(train_loader):\n",
        "            current_step_test += 1\n",
        "            logger.set_step(current_step, 'test')\n",
        "            imgs_view1, imgs_view2 = imgs_view1.to(config.device), imgs_view2.to(config.device)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                with torch.no_grad():\n",
        "                    loss, z_std1, z_std2 = criterion(imgs_view1, imgs_view2)\n",
        "\n",
        "            logger.add_scalar('loss', loss.item())\n",
        "            logger.add_scalar('std of z1', z_std1.item())\n",
        "            logger.add_scalar('std of z2', z_std2.item())\n",
        "\n",
        "        logger.add_image('img0', imgs_view1[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        logger.add_image('img1', imgs_view2[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        model_online.train()\n",
        "        model_predict.train()\n",
        "\n",
        "    if config.save_epochs != 0 and epoch % config.save_epochs == config.save_epochs - 1:\n",
        "        torch.save(model_online.state_dict(), f'{config.model_save_name}_{epoch}.pth')\n",
        "\n",
        "logger.finish()"
      ],
      "metadata": {
        "id": "4FB1bzPZroCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MOCO"
      ],
      "metadata": {
        "id": "tnR-sjKXrw_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = 1.0\n",
        "size = 96\n",
        "color_jitter = T.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
        "rnd_color_jitter = T.RandomApply([color_jitter], p=0.8)\n",
        "rnd_gray = T.RandomGrayscale(p=0.2)\n",
        "\n",
        "train_transforms = T.Compose([\n",
        "    T.RandomResizedCrop(size),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    rnd_color_jitter,\n",
        "    rnd_gray,\n",
        "    T.GaussianBlur(kernel_size=int(0.1 * 96)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "class ContrastiveImages():\n",
        "    def __init__(self, transform):\n",
        "        self.transform = transform\n",
        "        self.n_views = 2\n",
        "\n",
        "    def __call__(self, img):\n",
        "        return [self.transform(img) for i in range(self.n_views)]"
      ],
      "metadata": {
        "id": "8NNmRfrGrswM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class MOCO_config:\n",
        "    wandb_project: str = 'SLL_HW2'\n",
        "    num_workers: int = 16\n",
        "    device: str = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "    seed: int = 3407\n",
        "\n",
        "    num_epochs: int = 200\n",
        "    save_epochs: int = 10\n",
        "    eval_epochs: int = 10\n",
        "    batch_size: int = 1024\n",
        "    dim: int = 128\n",
        "    # K: int = 65536\n",
        "    K: int = 16384\n",
        "    temperature: float = 0.07\n",
        "    moving_average: float = 0.999\n",
        "\n",
        "    optim: str = 'SGD'\n",
        "    lr: float = 0.03\n",
        "    momentum: float = 0.9\n",
        "    weight_decay: float = 1e-4\n",
        "    \n",
        "    model_save_name: str = 'MOCO_2'"
      ],
      "metadata": {
        "id": "75CQuwfRsWV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MOCO_network(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(MOCO_network, self).__init__()\n",
        "\n",
        "        self.model_q = models.resnet18(num_classes=config.dim)\n",
        "        self.model_k = models.resnet18(num_classes=config.dim)\n",
        "\n",
        "        in_features = self.model_q.fc.in_features\n",
        "        self.model_q.fc = nn.Sequential(\n",
        "            nn.Linear(in_features, in_features),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features, config.dim)\n",
        "        )\n",
        "        self.model_k.fc = nn.Sequential(\n",
        "            nn.Linear(in_features, in_features),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features, config.dim)\n",
        "        )\n",
        "\n",
        "        for param_q, param_k in zip(self.model_q.parameters(), self.model_k.parameters()):\n",
        "            param_k.data.copy_(param_q.data)\n",
        "            param_k.requires_grad = False\n",
        "        \n",
        "        # self.queue = torch.randn(config.dim, config.K)\n",
        "        self.register_buffer(\"queue\", torch.randn(config.dim, config.K))\n",
        "        self.queue = F.normalize(self.queue, dim=0)\n",
        "        # self.queue_ptr = torch.zeros(1, dtype=torch.long)\n",
        "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
        "\n",
        "        self.N = config.batch_size\n",
        "        self.C = config.dim\n",
        "        self.T = config.temperature\n",
        "        self.device = config.device\n",
        "        self.K = config.K\n",
        "\n",
        "    def forward(self, q_imgs, k_imgs):\n",
        "        q = F.normalize(self.model_q(q_imgs), dim=1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for param_q, param_k in zip(self.model_q.parameters(), self.model_k.parameters()):\n",
        "                param_k.data = (param_k.data * config.moving_average + param_q.data * (1.0 - config.moving_average))\n",
        "        \n",
        "            # wo batch shuffling\n",
        "            k = F.normalize(self.model_k(k_imgs), dim=1)\n",
        "\n",
        "        l_pos = torch.bmm(q.view(self.N, 1, self.C), k.view(self.N, self.C, 1)).squeeze(-1)\n",
        "        l_neg = torch.mm(q.view(self.N, self.C), self.queue.clone().detach().view(self.C, self.K))\n",
        "        logits = torch.cat([l_pos, l_neg], dim=1)\n",
        "        logits /= self.T\n",
        "\n",
        "        labels = torch.zeros(logits.shape[0], dtype=torch.long).to(self.device)\n",
        "\n",
        "        assert self.K % self.N == 0\n",
        "        ptr = int(self.queue_ptr)\n",
        "        self.queue[:, ptr : ptr + self.N] = k.T\n",
        "        ptr = (ptr + self.N) % self.K\n",
        "        self.queue_ptr[0] = ptr\n",
        "\n",
        "        return logits, labels"
      ],
      "metadata": {
        "id": "JXtmcAbKsYv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = MOCO_config()\n",
        "set_random_seed(config.seed)\n",
        "# loader\n",
        "train_dataset = datasets.STL10('data', 'unlabeled', download=True, transform=ContrastiveImages(train_transforms))\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=True)\n",
        "\n",
        "test_dataset = datasets.STL10('data', 'train', download=True, transform=ContrastiveImages(train_transforms))\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=True)\n",
        "# models\n",
        "model = MOCO_network(config)\n",
        "model.to(config.device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), config.lr, momentum=config.momentum, weight_decay=config.weight_decay)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=len(train_loader))\n",
        "torch.backends.cudnn.benchmark = True\n",
        "current_step = 0\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "logger = WanDBWriter(config)\n",
        "tqdm_bar = tqdm(total=config.num_epochs * len(train_loader) - current_step)\n",
        "model.train()\n",
        "for epoch in range(config.num_epochs):\n",
        "    for i, ((q_imgs, k_imgs), label) in enumerate(train_loader):\n",
        "        current_step += 1\n",
        "        tqdm_bar.update(1)\n",
        "        logger.set_step(current_step)\n",
        "        q_imgs, k_imgs = q_imgs.to(config.device), k_imgs.to(config.device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output, target = model(q_imgs, k_imgs)\n",
        "            loss = criterion(output, target)\n",
        "            # print(loss)\n",
        "        \n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        accuracy = (predicted == target).sum().item() / len(target)\n",
        "\n",
        "        logger.add_scalar('loss', loss.item())\n",
        "        logger.add_scalar('accuracy', accuracy)\n",
        "    \n",
        "    if epoch >= 9:\n",
        "        scheduler.step()\n",
        "\n",
        "    logger.add_scalar('lr', optimizer.param_groups[0][\"lr\"])\n",
        "    logger.add_image('img0', q_imgs[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "    logger.add_image('img1', k_imgs[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "\n",
        "    # evaluate\n",
        "    if config.eval_epochs != 0 and epoch % config.eval_epochs == config.eval_epochs - 1:\n",
        "        model.eval()\n",
        "        current_step_test = 0\n",
        "        for i, ((q_imgs, k_imgs), label) in enumerate(train_loader):\n",
        "            current_step_test += 1\n",
        "            logger.set_step(current_step, 'test')\n",
        "            q_imgs, k_imgs = q_imgs.to(config.device), k_imgs.to(config.device)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                with torch.no_grad():\n",
        "                    output, target = model(q_imgs, k_imgs)\n",
        "                    loss = criterion(output, target)\n",
        "        \n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            accuracy = (predicted == target).sum().item() / len(target)\n",
        "\n",
        "            logger.add_scalar('loss', loss.item())\n",
        "            logger.add_scalar('accuracy', accuracy)\n",
        "\n",
        "        logger.add_image('img0', q_imgs[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        logger.add_image('img1', k_imgs[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        model.train()\n",
        "\n",
        "    if config.save_epochs != 0 and epoch % config.save_epochs == config.save_epochs - 1:\n",
        "        torch.save(model.state_dict(), f'{config.model_save_name}_{epoch}.pth')\n",
        "\n",
        "logger.finish()"
      ],
      "metadata": {
        "id": "wSerpKRSsc9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear probing\n",
        "\n",
        "## SimCLR"
      ],
      "metadata": {
        "id": "UpJdbOP0sgx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class SimCLR_LP_config:\n",
        "    wandb_project = 'SLL_HW2'\n",
        "    num_workers = 2\n",
        "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "    seed = 3407\n",
        "\n",
        "    num_epochs = 200\n",
        "    save_epochs = 20\n",
        "    eval_epochs = 10\n",
        "    batch_size = 256\n",
        "    optim = 'Adam'\n",
        "    lr = 3e-4\n",
        "    weight_decay = 1e-4\n",
        "\n",
        "    num_features = 512\n",
        "    model_load_path = \"model_SimCLR_2_89.pth\"\n",
        "    model_save_namne = \"model_SimCLR_2_89_LP\"\n",
        "    # scheduler = 'CosineAnnealingLR'"
      ],
      "metadata": {
        "id": "hat6L0FHskq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = SimCLR_LP_config()\n",
        "set_random_seed(config.seed)\n",
        "train_dataset = datasets.STL10('data', 'train', download=True, transform=T.ToTensor())\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=True)\n",
        "test_dataset = datasets.STL10('data', 'test', download=True, transform=T.ToTensor())\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True)\n",
        "\n",
        "model = models.resnet18(num_classes=config.num_features)\n",
        "in_features = model.fc.in_features\n",
        "projection_g = nn.Sequential(\n",
        "    nn.Linear(in_features, in_features),\n",
        "    nn.ReLU(),\n",
        "    model.fc\n",
        ")\n",
        "model.fc = projection_g\n",
        "model.load_state_dict(torch.load(config.model_load_path))\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.fc = nn.Linear(in_features, 10)\n",
        "model.to(config.device)\n",
        "\n",
        "# loss, optimizer and hyperparameters\n",
        "current_step = 0\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=config.momentum,\n",
        "#                       weight_decay=config.weight_decay, nesterov=True)\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
        "# scheduler = StepLR(optimizer, step_size=config.step_size, gamma=config.gamma)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "logger = WanDBWriter(config)\n",
        "# train\n",
        "tqdm_bar = tqdm(total=config.num_epochs * len(train_loader) - current_step)\n",
        "for epoch in range(config.num_epochs):\n",
        "    accuracy, loss = 0, 0\n",
        "    for i, (imgs, labels) in enumerate(train_loader):\n",
        "        current_step += 1\n",
        "        tqdm_bar.update(1)\n",
        "        logger.set_step(current_step)\n",
        "\n",
        "        imgs, labels = imgs.to(config.device), labels.to(config.device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "        # loss.backward()\n",
        "        # optimizer.step()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        accuracy += (predicted == labels).sum().item()\n",
        "        loss += loss.item()\n",
        "    \n",
        "    # scheduler.step()\n",
        "    logger.add_scalar('loss', loss / len(train_loader))\n",
        "    logger.add_scalar('accuracy', accuracy / len(train_loader) / config.batch_size)\n",
        "    logger.add_scalar('lr', optimizer.param_groups[0][\"lr\"])\n",
        "    logger.add_image('img0', imgs[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "    logger.add_image('img1', imgs[1].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "    logger.add_image('img2', imgs[2].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "\n",
        "    # evaluate\n",
        "    if config.eval_epochs != 0 and epoch % config.eval_epochs == config.eval_epochs - 1:\n",
        "        model.eval()\n",
        "        accuracy, loss = 0, 0\n",
        "        current_step_test = 0\n",
        "        for i, (imgs, labels) in enumerate(test_loader):\n",
        "            current_step_test += 1\n",
        "            logger.set_step(current_step, 'test')\n",
        "            imgs, labels = imgs.to(config.device), labels.to(config.device)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(imgs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "            \n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            accuracy += (predicted == labels).sum().item()\n",
        "            loss += loss.item()\n",
        "        \n",
        "        logger.add_scalar('loss', loss / len(test_loader))\n",
        "        logger.add_scalar('accuracy', accuracy / len(test_loader) / config.batch_size)\n",
        "        logger.add_image('img0', imgs[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        logger.add_image('img1', imgs[1].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        logger.add_image('img2', imgs[2].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        model.train()\n",
        "\n",
        "    if config.save_epochs != 0 and epoch % config.save_epochs == config.save_epochs - 1:\n",
        "        torch.save(model.state_dict(), f'{config.model_save_namne}_{epoch}.pth')\n",
        "\n",
        "logger.finish()"
      ],
      "metadata": {
        "id": "y51U3QAntioo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BYOL"
      ],
      "metadata": {
        "id": "S_fwXPEKtleB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class BYOL_LP_config:\n",
        "    wandb_project = 'SLL_HW2'\n",
        "    num_workers = 2\n",
        "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "    seed = 3407\n",
        "\n",
        "    num_epochs = 200\n",
        "    save_epochs = 20\n",
        "    eval_epochs = 10\n",
        "    batch_size = 256\n",
        "\n",
        "    optim = 'Adam'\n",
        "    lr = 3e-4\n",
        "    weight_decay = 1e-4\n",
        "\n",
        "    mlp_hidden_size = 4096\n",
        "    projection_size = 256\n",
        "    moving_average = 0.99\n",
        "\n",
        "    model_load_path = \"model_BYOL_oshibka_219.pth\"\n",
        "    model_save_name = \"model_BYOL_oshibka_219_LP\"\n",
        "\n",
        "    # scheduler = 'CosineAnnealingLR'"
      ],
      "metadata": {
        "id": "RRTfdqiPtkA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BYOL_network_LP(nn.Module):\n",
        "    def __init__(self, byol_model, in_features):\n",
        "        super(BYOL_network_LP, self).__init__()\n",
        "        self.byol_model = byol_model\n",
        "        for param in self.byol_model.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.fc = nn.Linear(in_features, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.byol_model(x)\n",
        "        x = x.view(x.shape[0], x.shape[1])\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "SbnUVTeAtnWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = BYOL_LP_config()\n",
        "set_random_seed(config.seed)\n",
        "train_dataset = datasets.STL10('data', 'train', download=True, transform=T.ToTensor())\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=True)\n",
        "test_dataset = datasets.STL10('data', 'test', download=True, transform=T.ToTensor())\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True)\n",
        "\n",
        "model = BYOL_network(config)\n",
        "model.load_state_dict(torch.load(config.model_load_path))\n",
        "in_features = model.in_features\n",
        "model = nn.Sequential(*list(model.children())[:-1])\n",
        "model = BYOL_network_LP(model, in_features)\n",
        "model.to(config.device)\n",
        "\n",
        "# loss, optimizer and hyperparameters\n",
        "current_step = 0\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=config.momentum,\n",
        "#                       weight_decay=config.weight_decay, nesterov=True)\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
        "# scheduler = StepLR(optimizer, step_size=config.step_size, gamma=config.gamma)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "logger = WanDBWriter(config)\n",
        "# train\n",
        "tqdm_bar = tqdm(total=config.num_epochs * len(train_loader) - current_step)\n",
        "for epoch in range(config.num_epochs):\n",
        "    accuracy, loss = 0, 0\n",
        "    for i, (imgs, labels) in enumerate(train_loader):\n",
        "        current_step += 1\n",
        "        tqdm_bar.update(1)\n",
        "        logger.set_step(current_step)\n",
        "\n",
        "        imgs, labels = imgs.to(config.device), labels.to(config.device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "        # loss.backward()\n",
        "        # optimizer.step()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        accuracy += (predicted == labels).sum().item()\n",
        "        loss += loss.item()\n",
        "    \n",
        "    # scheduler.step()\n",
        "    logger.add_scalar('loss', loss / len(train_loader))\n",
        "    logger.add_scalar('accuracy', accuracy / len(train_loader) / config.batch_size)\n",
        "    logger.add_scalar('lr', optimizer.param_groups[0][\"lr\"])\n",
        "    logger.add_image('img0', imgs[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "    logger.add_image('img1', imgs[1].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "    logger.add_image('img2', imgs[2].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "\n",
        "    # evaluate\n",
        "    if config.eval_epochs != 0 and epoch % config.eval_epochs == config.eval_epochs - 1:\n",
        "        model.eval()\n",
        "        accuracy, loss = 0, 0\n",
        "        current_step_test = 0\n",
        "        for i, (imgs, labels) in enumerate(test_loader):\n",
        "            current_step_test += 1\n",
        "            logger.set_step(current_step, 'test')\n",
        "            imgs, labels = imgs.to(config.device), labels.to(config.device)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(imgs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "            \n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            accuracy += (predicted == labels).sum().item()\n",
        "            loss += loss.item()\n",
        "        \n",
        "        logger.add_scalar('loss', loss / len(test_loader))\n",
        "        logger.add_scalar('accuracy', accuracy / len(test_loader) / config.batch_size)\n",
        "        logger.add_image('img0', imgs[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        logger.add_image('img1', imgs[1].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        logger.add_image('img2', imgs[2].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        model.train()\n",
        "\n",
        "    if config.save_epochs != 0 and epoch % config.save_epochs == config.save_epochs - 1:\n",
        "        torch.save(model.state_dict(), f'{config.model_save_name}_{epoch}.pth')\n",
        "\n",
        "logger.finish()"
      ],
      "metadata": {
        "id": "ZLZdhHnXtoda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MOCO"
      ],
      "metadata": {
        "id": "x7UTX78ktr__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class MOCO_LP_config:\n",
        "    wandb_project: str = 'SLL_HW2'\n",
        "    num_workers: int = 2\n",
        "    device: str = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "    seed: int = 3407\n",
        "\n",
        "    num_epochs: int = 200\n",
        "    save_epochs: int = 20\n",
        "    eval_epochs: int = 10\n",
        "    batch_size: int = 256\n",
        "    optim: str = 'Adam'\n",
        "    lr: float = 3e-4\n",
        "    weight_decay: float = 1e-4\n",
        "\n",
        "    dim: int = 128\n",
        "    K: int = 16384\n",
        "    temperature: float = 0.07\n",
        "    moving_average: float = 0.999\n",
        "\n",
        "    model_load_path: str = \"MOCO_2_199.pth\"\n",
        "    model_save_name: str = \"MOCO_2_199_LP\""
      ],
      "metadata": {
        "id": "jgTspbOUtsnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = MOCO_LP_config()\n",
        "set_random_seed(config.seed)\n",
        "\n",
        "transforms = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = datasets.STL10('data', 'train', download=True, transform=transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=True)\n",
        "test_dataset = datasets.STL10('data', 'test', download=True, transform=transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True)\n",
        "\n",
        "# models\n",
        "model = MOCO_network(config)\n",
        "model.load_state_dict(torch.load(config.model_load_path))\n",
        "model = model.model_q\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.fc = nn.Linear(model.fc[0].in_features, 10)\n",
        "model.to(config.device)\n",
        "\n",
        "# loss, optimizer and hyperparameters\n",
        "current_step = 0\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=config.momentum,\n",
        "#                       weight_decay=config.weight_decay, nesterov=True)\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
        "# scheduler = StepLR(optimizer, step_size=config.step_size, gamma=config.gamma)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "logger = WanDBWriter(config)\n",
        "# train\n",
        "tqdm_bar = tqdm(total=config.num_epochs * len(train_loader) - current_step)\n",
        "for epoch in range(config.num_epochs):\n",
        "    accuracy, loss = 0, 0\n",
        "    for i, (imgs, labels) in enumerate(train_loader):\n",
        "        current_step += 1\n",
        "        tqdm_bar.update(1)\n",
        "        logger.set_step(current_step)\n",
        "\n",
        "        imgs, labels = imgs.to(config.device), labels.to(config.device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(imgs)\n",
        "            loss_ = criterion(outputs, labels)\n",
        "        # loss.backward()\n",
        "        # optimizer.step()\n",
        "        scaler.scale(loss_).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        accuracy += (predicted == labels).sum().item()\n",
        "        loss += loss_.item()\n",
        "    \n",
        "    # scheduler.step()\n",
        "    logger.add_scalar('loss', loss / len(train_loader))\n",
        "    logger.add_scalar('accuracy', accuracy / len(train_loader) / config.batch_size)\n",
        "    logger.add_scalar('lr', optimizer.param_groups[0][\"lr\"])\n",
        "    logger.add_image('img0', imgs[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "    logger.add_image('img1', imgs[1].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "    logger.add_image('img2', imgs[2].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "\n",
        "    # evaluate\n",
        "    if config.eval_epochs != 0 and epoch % config.eval_epochs == config.eval_epochs - 1:\n",
        "        model.eval()\n",
        "        accuracy, loss = 0, 0\n",
        "        current_step_test = 0\n",
        "        for i, (imgs, labels) in enumerate(test_loader):\n",
        "            current_step_test += 1\n",
        "            logger.set_step(current_step, 'test')\n",
        "            imgs, labels = imgs.to(config.device), labels.to(config.device)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(imgs)\n",
        "                    loss_ = criterion(outputs, labels)\n",
        "            \n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            accuracy += (predicted == labels).sum().item()\n",
        "            loss += loss_.item()\n",
        "        \n",
        "        logger.add_scalar('loss', loss / len(test_loader))\n",
        "        logger.add_scalar('accuracy', accuracy / len(test_loader) / config.batch_size)\n",
        "        logger.add_image('img0', imgs[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        logger.add_image('img1', imgs[1].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        logger.add_image('img2', imgs[2].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        model.train()\n",
        "\n",
        "    if config.save_epochs != 0 and epoch % config.save_epochs == config.save_epochs - 1:\n",
        "        torch.save(model.state_dict(), f'{config.model_save_name}_{epoch}.pth')\n",
        "\n",
        "logger.finish()"
      ],
      "metadata": {
        "id": "CQa2dUxYtvAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning\n",
        "\n",
        "## SimCLR"
      ],
      "metadata": {
        "id": "Dq4MdVSgtyN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class SimCLR_FT_config:\n",
        "    wandb_project = 'SLL_HW2'\n",
        "    num_workers = 2\n",
        "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "    seed = 3407\n",
        "\n",
        "    num_epochs = 90\n",
        "    save_epochs = 10\n",
        "    eval_epochs = 10\n",
        "    batch_size = 256\n",
        "    optim = 'SGD'\n",
        "    nesterov = True\n",
        "    momentum = 0.9\n",
        "    lr = 0.05\n",
        "    weight_decay = 1e-4\n",
        "\n",
        "    num_features = 512\n",
        "    model_load_path = \"model_SimCLR_2_89.pth\"\n",
        "    model_save_name = \"model_SimCLR_2_89_FT\"\n",
        "\n",
        "    scheduler = 'MultiStepLR'\n",
        "    milestones = [30, 50, 70, 80]\n",
        "    gamma = 0.1"
      ],
      "metadata": {
        "id": "UiX_4vzdtzzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = T.Compose([\n",
        "    T.RandomResizedCrop(96),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "test_transforms = T.Compose([\n",
        "    T.Resize(110),\n",
        "    T.CenterCrop(96),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "WyhitMdyt3Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = SimCLR_FT_config()\n",
        "set_random_seed(config.seed)\n",
        "train_dataset = datasets.STL10('data', 'train', download=True, transform=train_transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=True)\n",
        "test_dataset = datasets.STL10('data', 'test', download=True, transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True)\n",
        "\n",
        "model = models.resnet18(num_classes=config.num_features)\n",
        "in_features = model.fc.in_features\n",
        "projection_g = nn.Sequential(\n",
        "    nn.Linear(in_features, in_features),\n",
        "    nn.ReLU(),\n",
        "    model.fc\n",
        ")\n",
        "model.fc = projection_g\n",
        "model.load_state_dict(torch.load(config.model_load_path))\n",
        "model.fc = nn.Linear(in_features, 10)\n",
        "model.to(config.device)\n",
        "\n",
        "# loss, optimizer and hyperparameters\n",
        "current_step = 0\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=config.momentum,\n",
        "                      weight_decay=config.weight_decay, nesterov=config.nesterov)\n",
        "scheduler = MultiStepLR(optimizer, milestones=config.milestones, gamma=config.gamma)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "logger = WanDBWriter(config)\n",
        "# train\n",
        "tqdm_bar = tqdm(total=config.num_epochs * len(train_loader) - current_step)\n",
        "for epoch in range(config.num_epochs):\n",
        "    accuracy, loss = 0, 0\n",
        "    for i, (imgs, labels) in enumerate(train_loader):\n",
        "        current_step += 1\n",
        "        tqdm_bar.update(1)\n",
        "        logger.set_step(current_step)\n",
        "\n",
        "        imgs, labels = imgs.to(config.device), labels.to(config.device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "        # loss.backward()\n",
        "        # optimizer.step()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        accuracy += (predicted == labels).sum().item()\n",
        "        loss += loss.item()\n",
        "    \n",
        "    scheduler.step()\n",
        "    logger.add_scalar('loss', loss / len(train_loader))\n",
        "    logger.add_scalar('accuracy', accuracy / len(train_loader) / config.batch_size)\n",
        "    logger.add_scalar('lr', optimizer.param_groups[0][\"lr\"])\n",
        "    logger.add_image('img0', imgs[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "    logger.add_image('img1', imgs[1].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "    logger.add_image('img2', imgs[2].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "\n",
        "    # evaluate\n",
        "    if config.eval_epochs != 0 and epoch % config.eval_epochs == config.eval_epochs - 1:\n",
        "        model.eval()\n",
        "        accuracy, loss = 0, 0\n",
        "        current_step_test = 0\n",
        "        for i, (imgs, labels) in enumerate(test_loader):\n",
        "            current_step_test += 1\n",
        "            logger.set_step(current_step, 'test')\n",
        "            imgs, labels = imgs.to(config.device), labels.to(config.device)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(imgs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "            \n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            accuracy += (predicted == labels).sum().item()\n",
        "            loss += loss.item()\n",
        "        \n",
        "        logger.add_scalar('loss', loss / len(test_loader))\n",
        "        logger.add_scalar('accuracy', accuracy / len(test_loader) / config.batch_size)\n",
        "        logger.add_image('img0', imgs[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        logger.add_image('img1', imgs[1].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        logger.add_image('img2', imgs[2].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        model.train()\n",
        "\n",
        "    if config.save_epochs != 0 and epoch % config.save_epochs == config.save_epochs - 1:\n",
        "        torch.save(model.state_dict(), f'{config.model_save_name}_{epoch}.pth')\n",
        "\n",
        "logger.finish()"
      ],
      "metadata": {
        "id": "ErcP7AK9t5DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BYOL"
      ],
      "metadata": {
        "id": "pGHrXoZ0t726"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class BYOL_FT_config:\n",
        "    wandb_project = 'SLL_HW2'\n",
        "    num_workers = 2\n",
        "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "    seed = 3407\n",
        "\n",
        "    num_epochs = 90\n",
        "    save_epochs = 10\n",
        "    eval_epochs = 10\n",
        "    batch_size = 256\n",
        "\n",
        "    optim = 'SGD'\n",
        "    nesterov = True\n",
        "    momentum = 0.9\n",
        "    lr = 0.05\n",
        "    weight_decay = 1e-4\n",
        "\n",
        "    mlp_hidden_size = 4096\n",
        "    projection_size = 256\n",
        "    moving_average = 0.99\n",
        "\n",
        "    model_load_path = \"model_BYOL_oshibka_219.pth\"\n",
        "    model_save_name = \"model_BYOL_oshibka_219_FT\"\n",
        "\n",
        "    scheduler = 'MultiStepLR'\n",
        "    milestones = [30, 50, 70, 80]\n",
        "    gamma = 0.1"
      ],
      "metadata": {
        "id": "lXKp_aSGt81T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = T.Compose([\n",
        "    T.RandomResizedCrop(96),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "test_transforms = T.Compose([\n",
        "    T.Resize(110),\n",
        "    T.CenterCrop(96),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "QzZzUg_zt-Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BYOL_network_FT(nn.Module):\n",
        "    def __init__(self, byol_model, in_features):\n",
        "        super(BYOL_network_FT, self).__init__()\n",
        "        self.byol_model = byol_model\n",
        "        self.fc = nn.Linear(in_features, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.byol_model(x)\n",
        "        x = x.view(x.shape[0], x.shape[1])\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "t95eEl35t_gV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = BYOL_FT_config()\n",
        "set_random_seed(config.seed)\n",
        "train_dataset = datasets.STL10('data', 'train', download=True, transform=train_transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=True)\n",
        "test_dataset = datasets.STL10('data', 'test', download=True, transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True)\n",
        "\n",
        "model = BYOL_network(config)\n",
        "model.load_state_dict(torch.load(config.model_load_path))\n",
        "in_features = model.in_features\n",
        "model = nn.Sequential(*list(model.children())[:-1])\n",
        "model = BYOL_network_FT(model, in_features)\n",
        "model.to(config.device)\n",
        "\n",
        "# loss, optimizer and hyperparameters\n",
        "current_step = 0\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=config.momentum,\n",
        "                      weight_decay=config.weight_decay, nesterov=config.nesterov)\n",
        "scheduler = MultiStepLR(optimizer, milestones=config.milestones, gamma=config.gamma)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "logger = WanDBWriter(config)\n",
        "# train\n",
        "tqdm_bar = tqdm(total=config.num_epochs * len(train_loader) - current_step)\n",
        "for epoch in range(config.num_epochs):\n",
        "    accuracy, loss = 0, 0\n",
        "    for i, (imgs, labels) in enumerate(train_loader):\n",
        "        current_step += 1\n",
        "        tqdm_bar.update(1)\n",
        "        logger.set_step(current_step)\n",
        "\n",
        "        imgs, labels = imgs.to(config.device), labels.to(config.device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "        # loss.backward()\n",
        "        # optimizer.step()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        accuracy += (predicted == labels).sum().item()\n",
        "        loss += loss.item()\n",
        "    \n",
        "    scheduler.step()\n",
        "    logger.add_scalar('loss', loss / len(train_loader))\n",
        "    logger.add_scalar('accuracy', accuracy / len(train_loader) / config.batch_size)\n",
        "    logger.add_scalar('lr', optimizer.param_groups[0][\"lr\"])\n",
        "    logger.add_image('img0', imgs[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "    logger.add_image('img1', imgs[1].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "    logger.add_image('img2', imgs[2].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "\n",
        "    # evaluate\n",
        "    if config.eval_epochs != 0 and epoch % config.eval_epochs == config.eval_epochs - 1:\n",
        "        model.eval()\n",
        "        accuracy, loss = 0, 0\n",
        "        current_step_test = 0\n",
        "        for i, (imgs, labels) in enumerate(test_loader):\n",
        "            current_step_test += 1\n",
        "            logger.set_step(current_step, 'test')\n",
        "            imgs, labels = imgs.to(config.device), labels.to(config.device)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(imgs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "            \n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            accuracy += (predicted == labels).sum().item()\n",
        "            loss += loss.item()\n",
        "        \n",
        "        logger.add_scalar('loss', loss / len(test_loader))\n",
        "        logger.add_scalar('accuracy', accuracy / len(test_loader) / config.batch_size)\n",
        "        logger.add_image('img0', imgs[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        logger.add_image('img1', imgs[1].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        logger.add_image('img2', imgs[2].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        model.train()\n",
        "\n",
        "    if config.save_epochs != 0 and epoch % config.save_epochs == config.save_epochs - 1:\n",
        "        torch.save(model.state_dict(), f'{config.model_save_name}_{epoch}.pth')\n",
        "\n",
        "logger.finish()"
      ],
      "metadata": {
        "id": "gtvmu9aEuAuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MOCO"
      ],
      "metadata": {
        "id": "Wa5B9HcuuCDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class MOCO_FT_config:\n",
        "    wandb_project: str = 'SLL_HW2'\n",
        "    num_workers: int = 2\n",
        "    device: str = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "    seed: int = 3407\n",
        "\n",
        "    num_epochs: int = 90\n",
        "    save_epochs: int = 10\n",
        "    eval_epochs: int = 10\n",
        "    batch_size: int = 256\n",
        "    optim: str = 'SGD'\n",
        "    nesterov: bool = True\n",
        "    momentum: float = 0.9\n",
        "    lr: float = 0.05\n",
        "    weight_decay: float = 1e-4\n",
        "\n",
        "    dim: int = 128\n",
        "    K: int = 16384\n",
        "    temperature: float = 0.07\n",
        "    moving_average: float = 0.999\n",
        "\n",
        "    scheduler = 'MultiStepLR'\n",
        "    milestones = [30, 50, 70, 80]\n",
        "    gamma = 0.1\n",
        "    \n",
        "    model_load_path: str = \"MOCO_2_199.pth\"\n",
        "    model_save_name: str = \"MOCO_2_199_FT\""
      ],
      "metadata": {
        "id": "-I8cVoJLuC0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = T.Compose([\n",
        "    T.RandomResizedCrop(96),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "test_transforms = T.Compose([\n",
        "    T.Resize(110),\n",
        "    T.CenterCrop(96),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "ZMe5p5JnuFa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = MOCO_FT_config()\n",
        "set_random_seed(config.seed)\n",
        "train_dataset = datasets.STL10('data', 'train', download=True, transform=train_transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=True)\n",
        "test_dataset = datasets.STL10('data', 'test', download=True, transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True)\n",
        "\n",
        "# models\n",
        "model = MOCO_network(config)\n",
        "model.load_state_dict(torch.load(config.model_load_path))\n",
        "model = model.model_q\n",
        "model.fc = nn.Linear(model.fc[0].in_features, 10)\n",
        "model.to(config.device)\n",
        "\n",
        "# loss, optimizer and hyperparameters\n",
        "current_step = 0\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=config.momentum,\n",
        "                      weight_decay=config.weight_decay, nesterov=config.nesterov)\n",
        "scheduler = MultiStepLR(optimizer, milestones=config.milestones, gamma=config.gamma)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "logger = WanDBWriter(config)\n",
        "# train\n",
        "tqdm_bar = tqdm(total=config.num_epochs * len(train_loader) - current_step)\n",
        "for epoch in range(config.num_epochs):\n",
        "    accuracy, loss = 0, 0\n",
        "    for i, (imgs, labels) in enumerate(train_loader):\n",
        "        current_step += 1\n",
        "        tqdm_bar.update(1)\n",
        "        logger.set_step(current_step)\n",
        "\n",
        "        imgs, labels = imgs.to(config.device), labels.to(config.device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(imgs)\n",
        "            loss_ = criterion(outputs, labels)\n",
        "        # loss.backward()\n",
        "        # optimizer.step()\n",
        "        scaler.scale(loss_).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        accuracy += (predicted == labels).sum().item()\n",
        "        loss += loss_.item()\n",
        "    \n",
        "    scheduler.step()\n",
        "    logger.add_scalar('loss', loss / len(train_loader))\n",
        "    logger.add_scalar('accuracy', accuracy / len(train_loader) / config.batch_size)\n",
        "    logger.add_scalar('lr', optimizer.param_groups[0][\"lr\"])\n",
        "    logger.add_image('img0', imgs[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "    logger.add_image('img1', imgs[1].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "    logger.add_image('img2', imgs[2].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "\n",
        "    # evaluate\n",
        "    if config.eval_epochs != 0 and epoch % config.eval_epochs == config.eval_epochs - 1:\n",
        "        model.eval()\n",
        "        accuracy, loss = 0, 0\n",
        "        current_step_test = 0\n",
        "        for i, (imgs, labels) in enumerate(test_loader):\n",
        "            current_step_test += 1\n",
        "            logger.set_step(current_step, 'test')\n",
        "            imgs, labels = imgs.to(config.device), labels.to(config.device)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(imgs)\n",
        "                    loss_ = criterion(outputs, labels)\n",
        "            \n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            accuracy += (predicted == labels).sum().item()\n",
        "            loss += loss_.item()\n",
        "        \n",
        "        logger.add_scalar('loss', loss / len(test_loader))\n",
        "        logger.add_scalar('accuracy', accuracy / len(test_loader) / config.batch_size)\n",
        "        logger.add_image('img0', imgs[0].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        logger.add_image('img1', imgs[1].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        logger.add_image('img2', imgs[2].detach().cpu().permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
        "        model.train()\n",
        "\n",
        "    if config.save_epochs != 0 and epoch % config.save_epochs == config.save_epochs - 1:\n",
        "        torch.save(model.state_dict(), f'{config.model_save_name}_{epoch}.pth')\n",
        "\n",
        "logger.finish()"
      ],
      "metadata": {
        "id": "qhNdliwRuGpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# t-SNE\n",
        "\n",
        "## Supervised"
      ],
      "metadata": {
        "id": "80KRkRPquNWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.manifold import TSNE\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "5lFFFgh6uIJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palette = sns.color_palette(\"dark\", 10)\n",
        "def draw_tsne(model, dataloder, title):\n",
        "    np.random.seed(3407)\n",
        "    random.seed(3407)\n",
        "    model.eval()\n",
        "    train_embeds = torch.tensor([], device='cuda:0')\n",
        "    train_labels = torch.tensor([], device='cuda:0')\n",
        "    for i, (imgs, labels) in enumerate(dataloder):\n",
        "        imgs, labels = imgs.to(config.device), labels.to(config.device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(imgs)\n",
        "            outputs = outputs.view((outputs.shape[0], outputs.shape[1]))\n",
        "            \n",
        "        train_embeds = torch.cat((train_embeds, outputs))\n",
        "        train_labels = torch.cat((train_labels, labels))\n",
        "    \n",
        "\n",
        "    index_to_label = {\n",
        "        0: \"airplane\", \n",
        "        1: \"bird\",\n",
        "        2: \"car\",\n",
        "        3: \"cat\",\n",
        "        4: \"deer\",\n",
        "        5: \"dog\",\n",
        "        6: \"horse\",\n",
        "        7: \"monkey\",\n",
        "        8: \"ship\",\n",
        "        9: \"truck\"\n",
        "    }\n",
        "\n",
        "    feat_cols = ['embed' + str(i) for i in range(train_embeds.shape[1]) ]\n",
        "\n",
        "    df = pd.DataFrame(train_embeds.cpu().tolist(), columns=feat_cols)\n",
        "    df['y'] = train_labels.cpu()\n",
        "    df['label'] = df['y'].apply(lambda i: index_to_label[int(i)])\n",
        "    df = df.sort_values(by=['label'])\n",
        "    \n",
        "    data = df[feat_cols].values\n",
        "    tsne = TSNE(n_jobs=-1, learning_rate='auto', init='pca')\n",
        "    tsne_results = tsne.fit_transform(data)\n",
        "\n",
        "    sns.color_palette(\"dark\")\n",
        "    df['tsne-2d-one'] = tsne_results[:,0]\n",
        "    df['tsne-2d-two'] = tsne_results[:,1]\n",
        "\n",
        "    plt.figure(figsize=(16,10))\n",
        "    sns.scatterplot(\n",
        "        x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
        "        hue=\"label\",\n",
        "        palette=palette,\n",
        "        data=df,\n",
        "        legend=\"full\",\n",
        "        alpha=0.3\n",
        "    ).set(title=title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "lGL9B-XwuSxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = SupervisedBaselineConfig()\n",
        "set_random_seed(config.seed)\n",
        "\n",
        "model = models.resnet18(num_classes=10)\n",
        "model.load_state_dict(torch.load('model_89.pth'))\n",
        "model = nn.Sequential(*list(model.children())[:-1])\n",
        "model.to(config.device)"
      ],
      "metadata": {
        "id": "EE0lFzuAuT4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.STL10('data', 'train', download=True, transform=test_transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "draw_tsne(model, train_loader, 'Supervised train')"
      ],
      "metadata": {
        "id": "DyK_Wa94ublx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = datasets.STL10('data', 'test', download=True, transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True)\n",
        "\n",
        "draw_tsne(model, test_loader, 'Supervised test')"
      ],
      "metadata": {
        "id": "j1K0Q-vTub2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SimCLR"
      ],
      "metadata": {
        "id": "TJg4ofUQuelj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class SimCLR_config:\n",
        "    wandb_project = 'SLL_HW2'\n",
        "    num_workers = 8\n",
        "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "    seed = 3407\n",
        "    \n",
        "    num_epochs = 200\n",
        "    save_epochs = 10\n",
        "    eval_epochs = 10\n",
        "    batch_size = 256\n",
        "    optim = 'Adam'\n",
        "    lr = 3e-4\n",
        "    weight_decay = 1e-4\n",
        "    \n",
        "    num_features = 512\n",
        "\n",
        "    scheduler = 'CosineAnnealingLR'\n",
        "    model_load_path = \"model_SimCLR_2_89.pth\"\n",
        "    model_save_namne = \"model_SimCLR_29_LP\""
      ],
      "metadata": {
        "id": "csZdkiuJudXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = SimCLR_config()\n",
        "set_random_seed(config.seed)\n",
        "\n",
        "model = models.resnet18(num_classes=config.num_features)\n",
        "in_features = model.fc.in_features\n",
        "projection_g = nn.Sequential(\n",
        "    nn.Linear(in_features, in_features),\n",
        "    nn.ReLU(),\n",
        "    model.fc\n",
        ")\n",
        "model.fc = projection_g\n",
        "model.load_state_dict(torch.load(config.model_load_path))\n",
        "model = nn.Sequential(*list(model.children())[:-1])\n",
        "model.to(config.device)"
      ],
      "metadata": {
        "id": "9UFcjKpLujBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = 1.0\n",
        "size = 96\n",
        "color_jitter = T.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
        "rnd_color_jitter = T.RandomApply([color_jitter], p=0.8)\n",
        "rnd_gray = T.RandomGrayscale(p=0.2)\n",
        "\n",
        "\n",
        "train_transforms = T.Compose([\n",
        "    T.RandomResizedCrop(size),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    rnd_color_jitter,\n",
        "    rnd_gray,\n",
        "    T.GaussianBlur(kernel_size=int(0.1 * size)),\n",
        "    T.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "lTgaxJs9ujQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.STL10('data', 'train', download=True, transform=train_transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "draw_tsne(model, train_loader, 'SimCLR train')"
      ],
      "metadata": {
        "id": "OlTZHw1wukXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = datasets.STL10('data', 'test', download=True, transform=train_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "draw_tsne(model, test_loader, 'SimCLR test')"
      ],
      "metadata": {
        "id": "wgjvEtBYulve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BYOL"
      ],
      "metadata": {
        "id": "-dAYDvJvuu4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class BYOL_config:\n",
        "    wandb_project = 'SLL_HW2'\n",
        "    num_workers = 2\n",
        "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "    seed = 3407\n",
        "\n",
        "    num_epochs = 1000\n",
        "    save_epochs = 20\n",
        "    eval_epochs = 20\n",
        "    batch_size = 512\n",
        "\n",
        "    optim = 'Adam'\n",
        "    lr = 3e-4\n",
        "    weight_decay = 1e-4\n",
        "\n",
        "    mlp_hidden_size = 4096\n",
        "    projection_size = 256\n",
        "    moving_average = 0.99\n",
        "\n",
        "    model_save_name = \"model_BYOL\"\n",
        "    model_load_path = \"model_BYOL_oshibka_219.pth\"\n",
        "    scheduler = 'CosineAnnealingLR'"
      ],
      "metadata": {
        "id": "cvyL9yT5utXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = BYOL_config()\n",
        "set_random_seed(config.seed)\n",
        "model = BYOL_network(config)\n",
        "model.load_state_dict(torch.load(config.model_load_path))\n",
        "model = nn.Sequential(*list(model.children())[:-1])\n",
        "model.to(config.device)"
      ],
      "metadata": {
        "id": "93rbHcSJuysj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.STL10('data', 'train', download=True, transform=train_transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "draw_tsne(model, train_loader, 'BYOL train')"
      ],
      "metadata": {
        "id": "hIlVDlNZu47i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = datasets.STL10('data', 'test', download=True, transform=train_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "draw_tsne(model, test_loader, 'BYOL test')"
      ],
      "metadata": {
        "id": "ndb8A0GQu5Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MOCO"
      ],
      "metadata": {
        "id": "IJytjkIju6rP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = MOCO_config()\n",
        "set_random_seed(config.seed)\n",
        "# loader\n",
        "train_dataset = datasets.STL10('data', 'train', download=True, transform=train_transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=True)\n",
        "\n",
        "test_dataset = datasets.STL10('data', 'test', download=True, transform=train_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=True)\n",
        "# models\n",
        "model = MOCO_network(config)\n",
        "model.load_state_dict(torch.load(config.model_load_path))\n",
        "model = nn.Sequential(*list(model.children())[:-1])\n",
        "model.to(config.device)"
      ],
      "metadata": {
        "id": "SiJsloWFu9pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_tsne(model, train_loader, 'MOCO train')"
      ],
      "metadata": {
        "id": "ufixIF87vAFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_tsne(model, test_loader, 'MOCO test')"
      ],
      "metadata": {
        "id": "lLvvfvbhvBQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SimCLR-FT"
      ],
      "metadata": {
        "id": "5frZvfopvDAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class SimCLR_FT_config:\n",
        "    wandb_project = 'SLL_HW2'\n",
        "    num_workers = 2\n",
        "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "    seed = 3407\n",
        "\n",
        "    num_epochs = 90\n",
        "    save_epochs = 10\n",
        "    eval_epochs = 10\n",
        "    batch_size = 256\n",
        "    optim = 'SGD'\n",
        "    nesterov = True\n",
        "    momentum = 0.9\n",
        "    lr = 0.05\n",
        "    weight_decay = 1e-4\n",
        "\n",
        "    num_features = 512\n",
        "    model_load_path = \"model_SimCLR_2_89_FT_59.pth\"\n",
        "\n",
        "    scheduler = 'MultiStepLR'\n",
        "    milestones = [30, 50, 70, 80]\n",
        "    gamma = 0.1"
      ],
      "metadata": {
        "id": "g4s3if5tvET6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = SimCLR_FT_config()\n",
        "set_random_seed(config.seed)\n",
        "\n",
        "model = models.resnet18(num_classes=10)\n",
        "model.load_state_dict(torch.load(config.model_load_path))\n",
        "model = nn.Sequential(*list(model.children())[:-1])\n",
        "model.to(config.device)"
      ],
      "metadata": {
        "id": "zhvKCj_cvIg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.STL10('data', 'train', download=True, transform=test_transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "draw_tsne(model, train_loader, 'SimCLR-FT train')"
      ],
      "metadata": {
        "id": "R1m5H6LkvJxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = datasets.STL10('data', 'test', download=True, transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "draw_tsne(model, test_loader, 'SimCLR-FT test')"
      ],
      "metadata": {
        "id": "4VYV5x_XvPc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BYOL-FT"
      ],
      "metadata": {
        "id": "jg9Dmr1tvR-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class BYOL_FT_config:\n",
        "    wandb_project = 'SLL_HW2'\n",
        "    num_workers = 2\n",
        "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "    seed = 3407\n",
        "\n",
        "    num_epochs = 90\n",
        "    save_epochs = 10\n",
        "    eval_epochs = 10\n",
        "    batch_size = 256\n",
        "\n",
        "    optim = 'SGD'\n",
        "    nesterov = True\n",
        "    momentum = 0.9\n",
        "    lr = 0.05\n",
        "    weight_decay = 1e-4\n",
        "\n",
        "    mlp_hidden_size = 4096\n",
        "    projection_size = 256\n",
        "    moving_average = 0.99\n",
        "\n",
        "    model_load_path = \"model_BYOL_oshibka_219_FT_79.pth\"\n",
        "    # model_save_name = \"model_BYOL_oshibka_219_FT\"\n",
        "\n",
        "    scheduler = 'MultiStepLR'\n",
        "    milestones = [30, 50, 70, 80]\n",
        "    gamma = 0.1"
      ],
      "metadata": {
        "id": "juzPWyNsvS78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = BYOL_FT_config()\n",
        "set_random_seed(config.seed)\n",
        "\n",
        "model = BYOL_network(config)\n",
        "in_features = model.in_features\n",
        "model = nn.Sequential(*list(model.children())[:-1])\n",
        "model = BYOL_network_FT(model, in_features)\n",
        "model.load_state_dict(torch.load(config.model_load_path))\n",
        "model = nn.Sequential(*list(model.children())[:-1])\n",
        "model.to(config.device)"
      ],
      "metadata": {
        "id": "Meo7n7FWvUQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.STL10('data', 'train', download=True, transform=test_transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "draw_tsne(model, train_loader, 'BYOL-FT train')"
      ],
      "metadata": {
        "id": "eE91w3DOvVbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = datasets.STL10('data', 'test', download=True, transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "draw_tsne(model, test_loader, 'BYOL-FT test')"
      ],
      "metadata": {
        "id": "pGSlHx1GvWrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MOCO"
      ],
      "metadata": {
        "id": "l2paWbTAvavb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class MOCO_FT_config:\n",
        "    wandb_project: str = 'SLL_HW2'\n",
        "    num_workers: int = 2\n",
        "    device: str = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "    seed: int = 3407\n",
        "\n",
        "    num_epochs: int = 90\n",
        "    save_epochs: int = 10\n",
        "    eval_epochs: int = 10\n",
        "    batch_size: int = 256\n",
        "    optim: str = 'SGD'\n",
        "    nesterov: bool = True\n",
        "    momentum: float = 0.9\n",
        "    lr: float = 0.05\n",
        "    weight_decay: float = 1e-4\n",
        "\n",
        "    dim: int = 128\n",
        "    K: int = 16384\n",
        "    temperature: float = 0.07\n",
        "    moving_average: float = 0.999\n",
        "\n",
        "    scheduler = 'MultiStepLR'\n",
        "    milestones = [30, 50, 70, 80]\n",
        "    gamma = 0.1\n",
        "    \n",
        "    model_load_path: str = \"MOCO_2_199_FT_89.pth\"\n",
        "    model_save_name: str = \"MOCO_2_199_FT\""
      ],
      "metadata": {
        "id": "x68KfjCPvc3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_transforms = T.Compose([\n",
        "    T.Resize(110),\n",
        "    T.CenterCrop(96),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "6HyB93-JveXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = MOCO_FT_config()\n",
        "set_random_seed(config.seed)\n",
        "\n",
        "model = models.resnet18(num_classes=10)\n",
        "model.load_state_dict(torch.load(config.model_load_path))\n",
        "model = nn.Sequential(*list(model.children())[:-1])\n",
        "model.to(config.device)"
      ],
      "metadata": {
        "id": "nMGZ6ShwvfqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.STL10('data', 'train', download=True, transform=test_transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "draw_tsne(model, train_loader, 'MOCO-FT train')"
      ],
      "metadata": {
        "id": "RJmpeJAZvgqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = datasets.STL10('data', 'test', download=True, transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "draw_tsne(model, test_loader, 'MOCO-FT test')"
      ],
      "metadata": {
        "id": "0mKaY38Nvhx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OOD robustness"
      ],
      "metadata": {
        "id": "TACadeU_vlQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ya cringe\n",
        "index_to_label = {\n",
        "    0: \"airplane\", \n",
        "    1: \"bird\",\n",
        "    2: \"car\",\n",
        "    3: \"cat\",\n",
        "    4: \"deer\",\n",
        "    5: \"dog\",\n",
        "    6: \"horse\",\n",
        "    7: \"monkey\",\n",
        "    8: \"ship\",\n",
        "    9: \"truck\"\n",
        "}\n",
        "\n",
        "index_to_label_cifar = {\n",
        "    0: \"airplane\",\n",
        "    1: \"automobile\",\n",
        "    2: \"bird\",\n",
        "    3: \"cat\",\n",
        "    4: \"deer\",\n",
        "    5: \"dog\",\n",
        "    6: \"frog\",\n",
        "    7: \"horse\",\n",
        "    8: \"ship\",\n",
        "    9: \"truck\"\n",
        "}\n",
        "\n",
        "cifar_index_to_stl_index = {\n",
        "    0: 0,\n",
        "    1: 2,\n",
        "    2: 1,\n",
        "    3: 3,\n",
        "    4: 4,\n",
        "    5: 5,\n",
        "    6: 7,\n",
        "    7: 6,\n",
        "    8: 8,\n",
        "    9: 9\n",
        "}\n",
        "\n",
        "def get_accuracy_cifar(model, test_loader, name):\n",
        "    model.eval()\n",
        "    accuracy = 0\n",
        "    for i, (imgs, labels) in enumerate(test_loader):\n",
        "        labels = torch.tensor([cifar_index_to_stl_index[x.item()] for x in labels])\n",
        "        imgs, labels = imgs.to(config.device), labels.to(config.device)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            with torch.no_grad():\n",
        "                outputs = model(imgs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        accuracy += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy for {name} = {accuracy / len(test_dataset)} on CIFAR-10')\n",
        "\n",
        "def get_accuracy_stl(model, test_loader, name):\n",
        "    model.eval()\n",
        "    accuracy = 0\n",
        "    for i, (imgs, labels) in enumerate(test_loader):\n",
        "        # labels = torch.tensor([cifar_index_to_stl_index[x.item()] for x in labels])\n",
        "        imgs, labels = imgs.to(config.device), labels.to(config.device)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            with torch.no_grad():\n",
        "                outputs = model(imgs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        accuracy += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy for {name} = {accuracy / len(test_dataset)} on STL-10\\n')"
      ],
      "metadata": {
        "id": "LMutJBQbvoeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supervised"
      ],
      "metadata": {
        "id": "XWYY-4DOvuNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_transforms = T.Compose([\n",
        "    T.Resize(256),\n",
        "    T.CenterCrop(224),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261])\n",
        "])\n",
        "\n",
        "config = SupervisedBaselineConfig()\n",
        "set_random_seed(config.seed)\n",
        "\n",
        "model = models.resnet18(num_classes=10)\n",
        "model.load_state_dict(torch.load('model_89.pth'))\n",
        "model.to(config.device)"
      ],
      "metadata": {
        "id": "gHOZ7jYjvrL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = datasets.STL10('data', 'test', transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "get_accuracy_stl(model, test_loader, 'Supervised')\n",
        "\n",
        "\n",
        "test_dataset = datasets.CIFAR10('data', 'test', transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "get_accuracy_cifar(model, test_loader, 'Supervised')"
      ],
      "metadata": {
        "id": "ZNCJ4EGvvv4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SimCLR-LP"
      ],
      "metadata": {
        "id": "WgMAut1zvxXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(num_classes=10)\n",
        "model.load_state_dict(torch.load('model_SimCLR_2_89_LP_199.pth'))\n",
        "model.to(config.device)\n",
        "\n",
        "test_transforms = T.Compose([\n",
        "    T.Resize(96),\n",
        "    T.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "as1Ffk4ovzoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = datasets.STL10('data', 'test', transform=T.ToTensor())\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "get_accuracy_stl(model, test_loader, 'CimCLR-LP')\n",
        "\n",
        "test_dataset = datasets.CIFAR10('data', 'test', transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "get_accuracy_cifar(model, test_loader, 'CimCLR-LP')"
      ],
      "metadata": {
        "id": "79j3tEfFv0Od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SimCLR-FT"
      ],
      "metadata": {
        "id": "qp4PDqAZv1j_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(num_classes=10)\n",
        "model.load_state_dict(torch.load('model_SimCLR_2_89_FT_59.pth'))\n",
        "model.to(config.device)"
      ],
      "metadata": {
        "id": "jhqHo8NSv3QF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_transforms = T.Compose([\n",
        "    T.Resize(110),\n",
        "    T.CenterCrop(96),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_dataset = datasets.STL10('data', 'test', transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "get_accuracy_stl(model, test_loader, 'CimCLR-FT')\n",
        "\n",
        "test_transforms = T.Compose([\n",
        "    T.Resize(110),\n",
        "    T.CenterCrop(96),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261])\n",
        "])\n",
        "\n",
        "test_dataset = datasets.CIFAR10('data', 'test', transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "get_accuracy_cifar(model, test_loader, 'CimCLR-FT')"
      ],
      "metadata": {
        "id": "DoNnLRv4v4dV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BYOL-LP"
      ],
      "metadata": {
        "id": "nQ6D-0jKv56p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class BYOL_FT_config:\n",
        "    wandb_project = 'SLL_HW2'\n",
        "    num_workers = 2\n",
        "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "    seed = 3407\n",
        "\n",
        "    num_epochs = 90\n",
        "    save_epochs = 10\n",
        "    eval_epochs = 10\n",
        "    batch_size = 256\n",
        "\n",
        "    optim = 'SGD'\n",
        "    nesterov = True\n",
        "    momentum = 0.9\n",
        "    lr = 0.05\n",
        "    weight_decay = 1e-4\n",
        "\n",
        "    mlp_hidden_size = 4096\n",
        "    projection_size = 256\n",
        "    moving_average = 0.99\n",
        "\n",
        "    model_load_path = \"model_BYOL_oshibka_219.pth\"\n",
        "    model_save_name = \"model_BYOL_oshibka_219_FT\"\n",
        "\n",
        "    scheduler = 'MultiStepLR'\n",
        "    milestones = [30, 50, 70, 80]\n",
        "    gamma = 0.1"
      ],
      "metadata": {
        "id": "7JMVwibcv7PH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = BYOL_FT_config()\n",
        "model = BYOL_network(config)\n",
        "in_features = model.in_features\n",
        "model = nn.Sequential(*list(model.children())[:-1])\n",
        "model = BYOL_network_FT(model, in_features)\n",
        "model.load_state_dict(torch.load('model_BYOL_oshibka_219_LP_199.pth'))\n",
        "model.to(config.device)"
      ],
      "metadata": {
        "id": "qOVOO42Rv81k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = datasets.STL10('data', 'test', transform=T.ToTensor())\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "get_accuracy_stl(model, test_loader, 'BYOL-LP')\n",
        "\n",
        "\n",
        "test_transforms = T.Compose([\n",
        "    T.Resize(96),\n",
        "    T.ToTensor(),\n",
        "])\n",
        "\n",
        "test_dataset = datasets.CIFAR10('data', 'test', transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "get_accuracy_cifar(model, test_loader, 'BYOL-LP')"
      ],
      "metadata": {
        "id": "65m1DD2wv9-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BYOL-FT"
      ],
      "metadata": {
        "id": "a1-w0Xnev_Lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = BYOL_FT_config()\n",
        "model = BYOL_network(config)\n",
        "in_features = model.in_features\n",
        "model = nn.Sequential(*list(model.children())[:-1])\n",
        "model = BYOL_network_FT(model, in_features)\n",
        "model.load_state_dict(torch.load('model_BYOL_oshibka_219_FT_79.pth'))\n",
        "model.to(config.device)"
      ],
      "metadata": {
        "id": "rNc8V8eJv__8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_transforms = T.Compose([\n",
        "    T.Resize(110),\n",
        "    T.CenterCrop(96),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_dataset = datasets.STL10('data', 'test', transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "get_accuracy_stl(model, test_loader, 'BYOL-FT')\n",
        "\n",
        "test_transforms = T.Compose([\n",
        "    T.Resize(110),\n",
        "    T.CenterCrop(96),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261])\n",
        "])\n",
        "\n",
        "test_dataset = datasets.CIFAR10('data', 'test', transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "get_accuracy_cifar(model, test_loader, 'BYOL-FT')"
      ],
      "metadata": {
        "id": "lmrEwXgBwBSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MOCO-LP"
      ],
      "metadata": {
        "id": "vXzCyWm7wClG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(num_classes=10)\n",
        "model.load_state_dict(torch.load('MOCO_2_199_LP_199.pth'))\n",
        "model.to(config.device)"
      ],
      "metadata": {
        "id": "4L-Vl78BwDwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_transforms = T.Compose([\n",
        "    T.Resize(96),\n",
        "    # T.CenterCrop(96),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_dataset = datasets.STL10('data', 'test', transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "get_accuracy_stl(model, test_loader, 'MOCO-LP')\n",
        "\n",
        "test_transforms = T.Compose([\n",
        "    T.Resize(96),\n",
        "    # T.CenterCrop(96),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261])\n",
        "])\n",
        "\n",
        "test_dataset = datasets.CIFAR10('data', 'test', download=True, transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "get_accuracy_cifar(model, test_loader, 'MOCO-LP')"
      ],
      "metadata": {
        "id": "qhoAtbCswHof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MOCO-FT"
      ],
      "metadata": {
        "id": "MGc0Bg_XwJXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(num_classes=10)\n",
        "model.load_state_dict(torch.load('MOCO_2_199_FT_89.pth'))\n",
        "model.to(config.device)"
      ],
      "metadata": {
        "id": "rjVB0r0gwH31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_transforms = T.Compose([\n",
        "    T.Resize(110),\n",
        "    T.CenterCrop(96),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_dataset = datasets.STL10('data', 'test', transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "get_accuracy_stl(model, test_loader, 'MOCO-FT')\n",
        "\n",
        "test_transforms = T.Compose([\n",
        "    T.Resize(110),\n",
        "    T.CenterCrop(96),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261])\n",
        "])\n",
        "\n",
        "test_dataset = datasets.CIFAR10('data', 'test', transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "get_accuracy_cifar(model, test_loader, 'MOCO-FT')"
      ],
      "metadata": {
        "id": "VyL0jDKQwLVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimum width"
      ],
      "metadata": {
        "id": "F6FIFptwwMj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import fmin_l_bfgs_b\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "def calc_loss(model):\n",
        "    # set_random_seed(config.seed)\n",
        "    model.eval()\n",
        "    model.to(config.device)\n",
        "    loss = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # print('start loss calculation')\n",
        "    for i, (imgs, labels) in enumerate(train_loader):\n",
        "        imgs, labels = imgs.to(config.device), labels.to(config.device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = model(imgs)\n",
        "            loss_ = criterion(outputs, labels)\n",
        "            # print(loss_)\n",
        "        loss += loss_.item()\n",
        "\n",
        "    # print('loss calculated, it is', loss / len(train_loader))\n",
        "    return loss / len(train_loader)\n",
        "\n",
        "\n",
        "def store_weights(x: np.ndarray):\n",
        "    # print('start model storing')\n",
        "    # set_random_seed(config.seed)\n",
        "    x_ = torch.tensor(x, dtype=torch.float32)\n",
        "    model.eval()\n",
        "    left_index = 0\n",
        "    for param in model.parameters():\n",
        "        param_size = param.data.size()\n",
        "        param_size_smooth = 1\n",
        "        for sz in param_size:\n",
        "            param_size_smooth *= sz\n",
        "        param.data = x_[left_index: left_index+param_size_smooth].view(param_size)\n",
        "        left_index += param_size_smooth\n",
        "    # print('model stored')\n",
        "    return model\n",
        "\n",
        "\n",
        "def calc_minus_loss_in_x(x: np.ndarray):\n",
        "    # print('hey')\n",
        "    model = store_weights(x)\n",
        "    # return (-1. * calc_loss(model), None)\n",
        "    return -1. * calc_loss(model)\n",
        "    # return (13, None) \n",
        "\n",
        "\n",
        "def calc_loss_and_grad(model):\n",
        "    # set_random_seed(config.seed)\n",
        "    model.eval()\n",
        "    model.to(config.device)\n",
        "    loss = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # print('start loss calculation')\n",
        "    for i, (imgs, labels) in enumerate(train_loader):\n",
        "        imgs, labels = imgs.to(config.device), labels.to(config.device)\n",
        "        \n",
        "        outputs = model(imgs)\n",
        "        loss_ = criterion(outputs, labels)\n",
        "        loss_.backward()\n",
        "\n",
        "        loss += loss_.item()\n",
        "\n",
        "    print('loss calculated, it is', loss / len(train_loader))\n",
        "    grad = torch.tensor([], device=config.device, dtype=torch.float64)\n",
        "    for param in model.parameters():\n",
        "        grad_param = param.grad.data.view(-1)\n",
        "        grad = torch.cat((grad, grad_param))\n",
        "\n",
        "    return loss / len(train_loader), grad.cpu() / len(train_loader)\n",
        "\n",
        "\n",
        "def calc_minus_loss_and_grad_in_x(x: np.ndarray):\n",
        "    # print('hey')\n",
        "    model = store_weights(x)\n",
        "    loss, grad = calc_loss_and_grad(model)\n",
        "    # print('loss', loss, 'grad shape', grad.shape, 'grad type', grad.dtype)\n",
        "    return -1. * loss, grad\n",
        "\n",
        "\n",
        "def calc_sharpness(model, train_loader, name, epsilon=1e-3):\n",
        "    # get x0 - minimum of function\n",
        "    x0 = torch.tensor([], device=config.device)\n",
        "    for param in model.parameters():\n",
        "        x0 = torch.cat((x0, param.data.view(-1)))\n",
        "    x0 = x0.detach().cpu().numpy()\n",
        "\n",
        "    # calc f(x_0)\n",
        "    f_x0 = calc_loss(model)\n",
        "    # let A be Identity matrix. Get x_min and x_max\n",
        "    x_min = x0 - epsilon * (np.abs(x0) + 1)\n",
        "    x_max = x0 + epsilon * (np.abs(x0) + 1)\n",
        "\n",
        "    # get f_x_max\n",
        "    bounds = np.concatenate([np.reshape(x_min, (x_min.shape[0], 1)),\n",
        "                         np.reshape(x_max, (x_max.shape[0], 1))], 1)\n",
        "\n",
        "    x_max, f_x_max, d = fmin_l_bfgs_b(func=calc_minus_loss_and_grad_in_x, x0=x0,\n",
        "                                    bounds=bounds, maxiter=10, m=10)\n",
        "    \n",
        "    # calc formula\n",
        "    f_x_max_real = -1.0 * f_x_max\n",
        "    sharpness = (f_x_max_real - f_x0) / (1 + f_x0) * 100.\n",
        "    # clear_output()\n",
        "    print(f'Sharpness for {name} model = {sharpness}')\n",
        "    return sharpness"
      ],
      "metadata": {
        "id": "8vQgzKQpwPPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supervised"
      ],
      "metadata": {
        "id": "GOYAAeJqwcCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_transforms = T.Compose([\n",
        "    T.Resize(256),\n",
        "    T.CenterCrop(224),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "config = SupervisedBaselineConfig()\n",
        "set_random_seed(config.seed)\n",
        "\n",
        "train_dataset = datasets.STL10('data', 'train', download=True, transform=test_transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=True)"
      ],
      "metadata": {
        "id": "uMaxxvjNwc79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(num_classes=10)\n",
        "model.load_state_dict(torch.load('model_89.pth'))\n",
        "model.to(config.device)\n",
        "\n",
        "sharpness = calc_sharpness(model, train_loader, 'Supervised', epsilon=1e-3)"
      ],
      "metadata": {
        "id": "vDop8OlbwfCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(num_classes=10)\n",
        "model.load_state_dict(torch.load('model_89.pth'))\n",
        "model.to(config.device)\n",
        "\n",
        "sharpness = calc_sharpness(model, train_loader, 'Supervised', epsilon=5e-4)"
      ],
      "metadata": {
        "id": "k7p7Yc1uwg-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SimCLR-LP"
      ],
      "metadata": {
        "id": "UenIkKYRwiQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = SimCLR_LP_config()\n",
        "model = models.resnet18(num_classes=10)\n",
        "model.load_state_dict(torch.load('model_SimCLR_2_89_LP_199.pth'))\n",
        "model.to(config.device)\n",
        "\n",
        "train_dataset = datasets.STL10('data', 'train', download=True, transform=T.ToTensor())\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=True)"
      ],
      "metadata": {
        "id": "aZr6jX7VwkK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sharpness = calc_sharpness(model, train_loader, 'SimCLR-LP', epsilon=1e-3)"
      ],
      "metadata": {
        "id": "U67cPfXjwmjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_SimCLR_2_89_LP_199.pth'))\n",
        "model.to(config.device)\n",
        "\n",
        "sharpness = calc_sharpness(model, train_loader, 'SimCLR-LP', epsilon=5e-4)"
      ],
      "metadata": {
        "id": "DDTCOE-ewoLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SimCLR-FT"
      ],
      "metadata": {
        "id": "bI9aXVeswrbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(num_classes=10)\n",
        "model.load_state_dict(torch.load('model_SimCLR_2_89_FT_59.pth'))\n",
        "model.to(config.device)\n",
        "\n",
        "test_transforms = T.Compose([\n",
        "    T.Resize(110),\n",
        "    T.CenterCrop(96),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_dataset = datasets.STL10('data', 'test', transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True, drop_last=False)"
      ],
      "metadata": {
        "id": "C49prwjVwsue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sharpness = calc_sharpness(model, test_loader, 'SimCLR-FT', epsilon=1e-3)"
      ],
      "metadata": {
        "id": "41ZS6Bnywuq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(num_classes=10)\n",
        "model.load_state_dict(torch.load('model_SimCLR_2_89_FT_59.pth'))\n",
        "model.to(config.device)\n",
        "\n",
        "sharpness = calc_sharpness(model, test_loader, 'SimCLR-FT', epsilon=5e-4)"
      ],
      "metadata": {
        "id": "vCTu_sKCwvxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BYOL-LP"
      ],
      "metadata": {
        "id": "ZrEeapX6wzuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.STL10('data', 'train', download=True, transform=T.ToTensor())\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=True)\n",
        "\n",
        "config = BYOL_FT_config()\n",
        "model = BYOL_network(config)\n",
        "in_features = model.in_features\n",
        "model = nn.Sequential(*list(model.children())[:-1])\n",
        "model = BYOL_network_FT(model, in_features)\n",
        "model.load_state_dict(torch.load('model_BYOL_oshibka_219_LP_199.pth'))\n",
        "model.to(config.device)\n",
        "\n",
        "sharpness = calc_sharpness(model, test_loader, 'BYOL-LP', epsilon=1e-3)"
      ],
      "metadata": {
        "id": "8cAewbhXw1Fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BYOL_network(config)\n",
        "in_features = model.in_features\n",
        "model = nn.Sequential(*list(model.children())[:-1])\n",
        "model = BYOL_network_FT(model, in_features)\n",
        "model.load_state_dict(torch.load('model_BYOL_oshibka_219_LP_199.pth'))\n",
        "model.to(config.device)\n",
        "\n",
        "sharpness = calc_sharpness(model, test_loader, 'BYOL-LP', epsilon=5e-4)"
      ],
      "metadata": {
        "id": "YN3i1-oxw34v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BYOL-FT"
      ],
      "metadata": {
        "id": "rgeRsVYqw50D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_transforms = T.Compose([\n",
        "    T.Resize(110),\n",
        "    T.CenterCrop(96),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = datasets.STL10('data', 'train', download=True, transform=test_transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=True, num_workers=config.num_workers, pin_memory=True, drop_last=True)"
      ],
      "metadata": {
        "id": "FNEOk857w5Mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = BYOL_FT_config()\n",
        "model = BYOL_network(config)\n",
        "in_features = model.in_features\n",
        "model = nn.Sequential(*list(model.children())[:-1])\n",
        "model = BYOL_network_FT(model, in_features)\n",
        "model.load_state_dict(torch.load('model_BYOL_oshibka_219_FT_79.pth'))\n",
        "model.to(config.device)\n",
        "\n",
        "sharpness = calc_sharpness(model, test_loader, 'BYOL-FT', epsilon=1e-3)"
      ],
      "metadata": {
        "id": "muN0ilcVw8gZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BYOL_network(config)\n",
        "in_features = model.in_features\n",
        "model = nn.Sequential(*list(model.children())[:-1])\n",
        "model = BYOL_network_FT(model, in_features)\n",
        "model.load_state_dict(torch.load('model_BYOL_oshibka_219_FT_79.pth'))\n",
        "model.to(config.device)\n",
        "\n",
        "sharpness = calc_sharpness(model, test_loader, 'BYOL-FT', epsilon=5e-4)"
      ],
      "metadata": {
        "id": "tNAoT0TIw9e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MOCO-LP"
      ],
      "metadata": {
        "id": "lNHVC4pgxAkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_transforms = T.Compose([\n",
        "    T.Resize(96),\n",
        "    # T.CenterCrop(96),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_dataset = datasets.STL10('data', 'test', transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True, drop_last=False)"
      ],
      "metadata": {
        "id": "2mrUPNifxBVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(num_classes=10)\n",
        "model.load_state_dict(torch.load('MOCO_2_199_LP_199.pth'))\n",
        "model.to(config.device)\n",
        "\n",
        "sharpness = calc_sharpness(model, test_loader, 'MOCO-LP', epsilon=1e-3)"
      ],
      "metadata": {
        "id": "-BgCa7aTxGae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(num_classes=10)\n",
        "model.load_state_dict(torch.load('MOCO_2_199_LP_199.pth'))\n",
        "model.to(config.device)\n",
        "\n",
        "sharpness = calc_sharpness(model, test_loader, 'MOCO-LP', epsilon=5e-4)"
      ],
      "metadata": {
        "id": "GywxePFlxHXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MOCO-FT\n",
        "\n"
      ],
      "metadata": {
        "id": "jb32FaCHxJVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_transforms = T.Compose([\n",
        "    T.Resize(110),\n",
        "    T.CenterCrop(96),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_dataset = datasets.STL10('data', 'test', transform=test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
        "                          shuffle=False, num_workers=config.num_workers, pin_memory=True, drop_last=False)"
      ],
      "metadata": {
        "id": "UyK0XyUUxIvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(num_classes=10)\n",
        "model.load_state_dict(torch.load('MOCO_2_199_FT_89.pth'))\n",
        "model.to(config.device)\n",
        "\n",
        "sharpness = calc_sharpness(model, test_loader, 'MOCO-FT', epsilon=1e-3)"
      ],
      "metadata": {
        "id": "_nAe2jzKxPZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(num_classes=10)\n",
        "model.load_state_dict(torch.load('MOCO_2_199_FT_89.pth'))\n",
        "model.to(config.device)\n",
        "\n",
        "sharpness = calc_sharpness(model, test_loader, 'MOCO-FT', epsilon=5e-4)"
      ],
      "metadata": {
        "id": "b2ddPGUsxQhi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}